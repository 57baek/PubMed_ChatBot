{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "pRaykAACSbuY"
      },
      "source": [
        "\n",
        "\n",
        "# Building a healthcare chatbot with Mixtral 8x7b, Haystack, and PubMed\n",
        "\n",
        "\n",
        "*notebook by Tilde Thurium:\n",
        " [Mastodon](https://tech.lgbt/@annthurium) || [Twitter](https://twitter.com/annthurium) || [LinkedIn](https://www.linkedin.com/in/annthurium/)*\n",
        "\n",
        "##Introduction\n",
        "**ðŸ“š Check out the [Building a healthcare chatbot with Mixtral 8x7b, Haystack, and PubMed](https://haystack.deepset.ai/blog/mixtral-8x7b-healthcare-chatbot) article for a detailed run through of this example.**\n",
        "\n",
        "**Prerequisites:**\n",
        "\n",
        "*   [HuggingFace Access Token](https://huggingface.co/settings/tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kobrp6O3SbuY"
      },
      "source": [
        "## Installing Haystack\n",
        "\n",
        "To start, let's install the latest release of Haystack with `pip`, as well as any other libraries we're going to need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFb8fAhmSbuY",
        "outputId": "2e61d75e-2b70-42a3-ee38-cc7e683c9844"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "pip install haystack-ai\n",
        "pip install pymed\n",
        "pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTiZXeHbpN1I"
      },
      "source": [
        "This asks for keys the notebook needs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOynyZ__t_X5",
        "outputId": "98cf3e1f-81a1-428f-d87c-cb37a0062dd1"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "huggingface_token = getpass(\"Enter your Hugging Face api token:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Rc2FY_Cvq8m"
      },
      "source": [
        "# PubMed Fetcher\n",
        "\n",
        "PubMed is the best source of up to date medical research. Now we are going to write our own custom class to pull scientific papers from PubMed that are relevant to the query at hand.\n",
        "\n",
        "The PubMed sdk basically just wraps the PubMed API so it's easier to query.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FELyF-Z0NT4X"
      },
      "outputs": [],
      "source": [
        "# pymed â†’ A library for querying PubMed articles.\n",
        "# List â†’ Used for type hinting to specify lists.\n",
        "# haystack.component â†’ Defines reusable Haystack components.\n",
        "# haystack.Document â†’ A class that stores the text content and metadata of a document.\n",
        "from pymed import PubMed\n",
        "from typing import List\n",
        "from haystack import component\n",
        "from haystack import Document\n",
        "\n",
        "pubmed = PubMed(tool=\"Haystack2.0Prototype\", email=\"tilde.thurium@deepset.ai\")\n",
        "\n",
        "def documentize(article):\n",
        "  return Document(content=article.abstract, meta={'title': article.title, 'keywords': article.keywords})\n",
        "\n",
        "@component\n",
        "class PubMedFetcher():\n",
        "\n",
        "  @component.output_types(articles=List[Document])\n",
        "  def run(self, queries: list[str]):\n",
        "    cleaned_queries = queries[0].strip().split('\\n')\n",
        "\n",
        "    articles = []\n",
        "    try:\n",
        "      for query in cleaned_queries:\n",
        "        response = pubmed.query(query, max_results = 1)\n",
        "        documents = [documentize(article) for article in response]\n",
        "        articles.extend(documents)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        print(f\"Couldn't fetch articles for queries: {queries}\" )\n",
        "    results = {'articles': articles}\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwK9hBa-k98w"
      },
      "source": [
        "Now we add our `PubmedFetcher` into a pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "lKvIKg6S1VRG",
        "outputId": "12ad199a-d72b-4c0e-b423-272119fcb422"
      },
      "outputs": [],
      "source": [
        "from haystack.components.generators import HuggingFaceTGIGenerator\n",
        "from haystack.utils import Secret\n",
        "\n",
        "\n",
        "keyword_llm = HuggingFaceTGIGenerator(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", token=Secret.from_token(huggingface_token))\n",
        "keyword_llm.warm_up()\n",
        "\n",
        "llm = HuggingFaceTGIGenerator(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", token=Secret.from_token(huggingface_token))\n",
        "llm.warm_up()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWCYd6hOpoIn"
      },
      "outputs": [],
      "source": [
        "from haystack import Pipeline\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "\n",
        "keyword_prompt_template = \"\"\"\n",
        "Your task is to convert the following question into 3 keywords that can be used to find relevant medical research papers on PubMed.\n",
        "Here is an examples:\n",
        "question: \"What are the latest treatments for major depressive disorder?\"\n",
        "keywords:\n",
        "Antidepressive Agents\n",
        "Depressive Disorder, Major\n",
        "Treatment-Resistant depression\n",
        "---\n",
        "question: {{ question }}\n",
        "keywords:\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Answer the question truthfully based on the given documents.\n",
        "If the documents don't contain an answer, use your existing knowledge base.\n",
        "\n",
        "q: {{ question }}\n",
        "Articles:\n",
        "{% for article in articles %}\n",
        "  {{article.content}}\n",
        "  keywords: {{article.meta['keywords']}}\n",
        "  title: {{article.meta['title']}}\n",
        "{% endfor %}\n",
        "\n",
        "\"\"\"\n",
        "keyword_prompt_builder = PromptBuilder(template=keyword_prompt_template)\n",
        "\n",
        "prompt_builder = PromptBuilder(template=prompt_template)\n",
        "fetcher = PubMedFetcher()\n",
        "\n",
        "pipe = Pipeline()\n",
        "\n",
        "pipe.add_component(\"keyword_prompt_builder\", keyword_prompt_builder)\n",
        "pipe.add_component(\"keyword_llm\", keyword_llm)\n",
        "pipe.add_component(\"pubmed_fetcher\", fetcher)\n",
        "pipe.add_component(\"prompt_builder\", prompt_builder)\n",
        "pipe.add_component(\"llm\", llm)\n",
        "\n",
        "pipe.connect(\"keyword_prompt_builder.prompt\", \"keyword_llm.prompt\")\n",
        "pipe.connect(\"keyword_llm.replies\", \"pubmed_fetcher.queries\")\n",
        "\n",
        "pipe.connect(\"pubmed_fetcher.articles\", \"prompt_builder.articles\")\n",
        "pipe.connect(\"prompt_builder.prompt\", \"llm.prompt\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1hTVeYpmVRH"
      },
      "source": [
        "\n",
        "While we're at it, let's make an `ask` method to wrap our query fetching. This method makes it easy to pull the query response out of the results and highlighting the answer in blue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6y2xvz2VJOT"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML\n",
        "\n",
        "def ask(question):\n",
        "  output = pipe.run(data={\"keyword_prompt_builder\":{\"question\":question},\n",
        "                          \"prompt_builder\":{\"question\": question},\n",
        "                          \"llm\":{\"generation_kwargs\": {\"max_new_tokens\": 500}}})\n",
        "  print(question)\n",
        "  print(output['llm']['replies'][0])\n",
        "  # display(HTML(f'<div style=\"color: blue\">{output[\"llm\"]['replies'][0]}</div>'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEbStD7jmb_L"
      },
      "source": [
        "Give it a try!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUPghrs9Vm8w",
        "outputId": "1b6d70d6-4f99-4dd8-de3d-034754c62147"
      },
      "outputs": [],
      "source": [
        "ask(\"How are mRNA vaccines being used for cancer treatment?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFGaPu6yqHEs"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJG3DW3jnXXr"
      },
      "source": [
        "**What's next**\n",
        "\n",
        "In this tutorial, you learned to make a basic chatbot using a custom Haystack Retriever that pulls data from PubMed. In order to make this chatbot fancier, you could make improvements like:\n",
        "\n",
        "\n",
        "*   Adding additional data sources\n",
        "*   Giving the bot a name or personality\n",
        "*   Making it a [stateful agent so it remembers past queries](https://docs.haystack.deepset.ai/docs/agent#conversational-agent-memory)\n",
        "\n",
        "To see what else is possible with Haystack, you can [browse these tutorials](https://haystack.deepset.ai/tutorials) or check us out on [GitHub](https://github.com/deepset-ai/haystack). Thanks for reading!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "bda33b16be7e844498c7c2d368d72665b4f1d165582b9547ed22a0249a29ca2e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
