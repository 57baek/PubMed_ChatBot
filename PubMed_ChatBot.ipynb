{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed Research Assistant Chatbot Using LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Settings and Credentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-05T05:36:25.882274Z",
     "iopub.status.busy": "2025-02-05T05:36:25.881842Z",
     "iopub.status.idle": "2025-02-05T05:36:42.732297Z",
     "shell.execute_reply": "2025-02-05T05:36:42.731205Z",
     "shell.execute_reply.started": "2025-02-05T05:36:25.882239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip install haystack-ai\n",
    "pip install pymed\n",
    "pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T05:37:01.690293Z",
     "iopub.status.busy": "2025-02-05T05:37:01.689904Z",
     "iopub.status.idle": "2025-02-05T05:37:02.214410Z",
     "shell.execute_reply": "2025-02-05T05:37:02.213223Z",
     "shell.execute_reply.started": "2025-02-05T05:37:01.690263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PubMed Fetcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run \"export NCBI_API_KEY=\"your_actual_api_key\" with the actual api key on terminal\n",
    "\n",
    "### max_results can be adjusted to specify how many articles you want to retrieve for each query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pymed import PubMed\n",
    "from typing import List\n",
    "from haystack import component\n",
    "from haystack import Document\n",
    "import os\n",
    "\n",
    "api_key = os.getenv(\"NCBI_API_KEY\")  \n",
    "\n",
    "pubmed = PubMed(tool=\"PubMed_ChatBot\", email=\"hxb294@case.edu\")\n",
    "pubmed.api_key = api_key\n",
    "\n",
    "# CHANGE\n",
    "max_results = 1 # CHANGE\n",
    "\n",
    "def documentize(article):\n",
    "  return Document(content=article.abstract, meta={'title': article.title, 'keywords': article.keywords})\n",
    "\n",
    "@component\n",
    "class PubMedFetcher():\n",
    "  \n",
    "  @component.output_types(articles=List[Document])\n",
    "  def run(self, queries: list[str]):\n",
    "    cleaned_queries = queries[0].strip().split('\\n')\n",
    "    articles = []\n",
    "    try:\n",
    "      for query in cleaned_queries:\n",
    "        response = pubmed.query(query, max_results)\n",
    "        documents = [documentize(article) for article in response]\n",
    "        articles.extend(documents)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f\"Couldn't fetch articles for queries: {queries}\" )\n",
    "    \n",
    "    results = {'articles': articles}\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from haystack.components.generators import HuggingFaceTGIGenerator\n",
    "\n",
    "# CHANGE\n",
    "keyword_llm = HuggingFaceTGIGenerator(model = \"mistralai/Mixtral-8x7B-Instruct-v0.1\") # CHANGE\n",
    "keyword_llm.warm_up()\n",
    "\n",
    "# CHANGE\n",
    "llm = HuggingFaceTGIGenerator(model = \"mistralai/Mixtral-8x7B-Instruct-v0.1\") # CHANGE\n",
    "llm.warm_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Templates\n",
    "\n",
    "### Change num_keywords value to set the number of keywords dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CHANGE\n",
    "num_keywords = 1 # CHANGE\n",
    "\n",
    "keyword_prompt_template = f\"\"\"\n",
    "Your task is to convert the following question into {num_keywords} keywords that can be used to find relevant medical research papers on PubMed.\n",
    "Here is an example:\n",
    "question: \"What are the latest treatments for major depressive disorder?\"\n",
    "keywords:\n",
    "Antidepressive Agents\n",
    "Depressive Disorder, Major\n",
    "Treatment-Resistant depression\n",
    "---\n",
    "question: {{ question }}\n",
    "keywords:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "Answer the question truthfully based on the given documents.\n",
    "If the documents don't contain an answer, use your existing knowledge base.\n",
    "q: {{ question }}\n",
    "Articles:\n",
    "{% for article in articles %}\n",
    "  {{article.content}}\n",
    "  keywords: {{article.meta['keywords']}}\n",
    "  title: {{article.meta['title']}}\n",
    "{% endfor %}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "\n",
    "keyword_prompt_builder = PromptBuilder(template=keyword_prompt_template)\n",
    "prompt_builder = PromptBuilder(template=prompt_template)\n",
    "\n",
    "fetcher = PubMedFetcher()\n",
    "\n",
    "pipe = Pipeline()\n",
    "\n",
    "pipe.add_component(\"keyword_prompt_builder\", keyword_prompt_builder)\n",
    "pipe.add_component(\"keyword_llm\", keyword_llm)\n",
    "pipe.add_component(\"pubmed_fetcher\", fetcher)\n",
    "pipe.add_component(\"prompt_builder\", prompt_builder)\n",
    "pipe.add_component(\"llm\", llm)\n",
    "\n",
    "pipe.connect(\"keyword_prompt_builder.prompt\", \"keyword_llm.prompt\")\n",
    "pipe.connect(\"keyword_llm.replies\", \"pubmed_fetcher.queries\")\n",
    "\n",
    "pipe.connect(\"pubmed_fetcher.articles\", \"prompt_builder.articles\")\n",
    "pipe.connect(\"prompt_builder.prompt\", \"llm.prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seek and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CHANGE\n",
    "max_new_tokens = 100 # CHANGE\n",
    "\n",
    "def ask(question):\n",
    "  output = pipe.run(data = {\"keyword_prompt_builder\": {\"question\": question},\n",
    "                            \"prompt_builder\": {\"question\": question},\n",
    "                            \"llm\": {\"generation_kwargs\": {\"max_new_tokens\": max_new_tokens}}})\n",
    "  print(question)\n",
    "  print(output['llm']['replies'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ye shall find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ask(\"How are mRNA vaccines being used for cancer treatment?\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
